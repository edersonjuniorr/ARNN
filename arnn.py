# -*- coding: utf-8 -*-
"""ARNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mK8Kcx7VfkssfETkrvd449yKMztYEe6n
"""

pip install librosa numpy scikit-learn pydub tensorflow

import librosa
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_curve, auc
import os
from pydub import AudioSegment
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, label_binarize
from tensorflow import keras
from tensorflow.keras import layers

# Função para converter MP3 para WAV
def converter_mp3_para_wav(arquivo_mp3, arquivo_wav):
    if not os.path.exists(arquivo_wav):
        sound = AudioSegment.from_mp3(arquivo_mp3)
        sound.export(arquivo_wav, format="wav")

# Função para extrair características MFCCs
def extrair_mfccs(arquivo_audio):
    y, sr = librosa.load(arquivo_audio, duration=20)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    return np.mean(mfccs.T, axis=0)

# Função para carregar dados, rótulos e nomes de arquivos
def carregar_dados(diretorio, classe_alvo):
    dados = []
    rotulos = []
    nomes_arquivos = []
    for arquivo in os.listdir(diretorio):
        if arquivo.endswith('.mp3'):
            arquivo_mp3 = os.path.join(diretorio, arquivo)
            arquivo_wav = arquivo_mp3.replace('.mp3', '.wav')
            converter_mp3_para_wav(arquivo_mp3, arquivo_wav)
            mfccs = extrair_mfccs(arquivo_wav)
            dados.append(mfccs)
            rotulos.append(classe_alvo)
            nomes_arquivos.append(arquivo)
    return np.array(dados), np.array(rotulos), nomes_arquivos

dados_vf, rotulos_vf, nomes_vf = carregar_dados('data/voz_feminina', 'voz_feminina')
dados_vm, rotulos_vm, nomes_vm = carregar_dados('data/voz_masculina', 'voz_masculina')
dados_g, rotulos_g, nomes_g = carregar_dados('data/guitarra', 'guitarra')

# Combinar dados e rótulos
dados_total = np.concatenate((dados_vf, dados_vm, dados_g))
rotulos_total = np.concatenate((rotulos_vf, rotulos_vm, rotulos_g))
nomes_total = np.concatenate((nomes_vf, nomes_vm, nomes_g))

# Codificar rótulos
label_encoder = LabelEncoder()
rotulos_encoded = label_encoder.fit_transform(rotulos_total)
rotulos_bin = label_binarize(rotulos_encoded, classes=np.unique(rotulos_encoded))

# Dividir dados em treinamento e teste
dados_treino, dados_teste, rotulos_treino, rotulos_teste, nomes_treino, nomes_teste = train_test_split(
    dados_total, rotulos_encoded, nomes_total, test_size=0.2, stratify=rotulos_encoded
)
rotulos_teste_bin = label_binarize(rotulos_teste, classes=np.unique(rotulos_encoded))


# Construir modelo de rede neural
modelo = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(40,)),
    layers.Dropout(0.5),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(len(np.unique(rotulos_encoded)), activation='softmax')
])

# Compilar modelo
modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Treinar modelo
historico = modelo.fit(dados_treino, rotulos_treino, epochs=25, validation_split=0.2, verbose=1)

# Fazer previsões
previsoes_probs = modelo.predict(dados_teste)
previsoes = np.argmax(previsoes_probs, axis=1)

# Avaliar modelo
acuracia = accuracy_score(rotulos_teste, previsoes)
print(f'Acurácia: {acuracia}')

# Comparar predições com rótulos verdadeiros
acertos = []
erros = []
for i in range(len(rotulos_teste)):
    rotulo_verdadeiro = label_encoder.inverse_transform([rotulos_teste[i]])[0]
    rotulo_previsto = label_encoder.inverse_transform([previsoes[i]])[0]
    if rotulo_verdadeiro == rotulo_previsto:
        acertos.append(f"{nomes_teste[i]} (Previsto: {rotulo_previsto})")
    else:
        erros.append(f"{nomes_teste[i]} (Verdadeiro: {rotulo_verdadeiro}, Previsto: {rotulo_previsto})")

# Criar gráfico de barras
plt.figure(figsize=(10, 6))
plt.bar(['Acertos', 'Erros'], [len(acertos), len(erros)])
plt.title('Acertos e Erros no Conjunto de Teste')
plt.ylabel('Número de Arquivos')
plt.show()

# Imprimir detalhes de acertos e erros
print("\nAcertos:")
for acerto in acertos:
    print(acerto)

print("\nErros:")
for erro in erros:
    print(erro)

# Calcular ROC e AUC
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(rotulos_encoded))):
    fpr[i], tpr[i], _ = roc_curve(rotulos_teste_bin[:, i], previsoes_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plotar ROC
plt.figure(figsize=(8, 6))
for i in range(len(np.unique(rotulos_encoded))):
    plt.plot(fpr[i], tpr[i], label=f'ROC curve (class {label_encoder.classes_[i]}) (AUC = {roc_auc[i]:0.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falso Positivo')
plt.ylabel('Taxa de Verdadeiro Positivo')
plt.title('Curva ROC para Cada Classe')
plt.legend(loc="lower right")
plt.show()

# Gráfico de histórico de treinamento
plt.plot(historico.history['accuracy'], label='Acurácia de treinamento')
plt.plot(historico.history['val_accuracy'], label='Acurácia de validação')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()
plt.show()